{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","mount_file_id":"1mr-2wLnvN6ddyAXJNwARfZmw8uM_Lg6M","authorship_tag":"ABX9TyNHPisWp4BjGGYvD5YqFpoV"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","source":["!pip install roboflow\n","\n","from roboflow import Roboflow\n","rf = Roboflow(api_key=\"qN4kXsL6ciaQC2x0nvIA\")\n","project = rf.workspace(\"chenweiang\").project(\"facemask-un0wp\")\n","dataset = project.version(1).download(\"yolov8\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"8H5iX5xsk9Wm","executionInfo":{"status":"ok","timestamp":1694689681396,"user_tz":-180,"elapsed":22837,"user":{"displayName":"M Elbaz","userId":"12079689995044965838"}},"outputId":"734f521c-d5f7-4bf3-d244-dfeb9734fa50"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting roboflow\n","  Downloading roboflow-1.1.6-py3-none-any.whl (58 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.7/58.7 kB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting certifi==2022.12.7 (from roboflow)\n","  Downloading certifi-2022.12.7-py3-none-any.whl (155 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m155.3/155.3 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting chardet==4.0.0 (from roboflow)\n","  Downloading chardet-4.0.0-py2.py3-none-any.whl (178 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m178.7/178.7 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting cycler==0.10.0 (from roboflow)\n","  Downloading cycler-0.10.0-py2.py3-none-any.whl (6.5 kB)\n","Collecting idna==2.10 (from roboflow)\n","  Downloading idna-2.10-py2.py3-none-any.whl (58 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.8/58.8 kB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.10/dist-packages (from roboflow) (1.4.5)\n","Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from roboflow) (3.7.1)\n","Requirement already satisfied: numpy>=1.18.5 in /usr/local/lib/python3.10/dist-packages (from roboflow) (1.23.5)\n","Collecting opencv-python-headless==4.8.0.74 (from roboflow)\n","  Downloading opencv_python_headless-4.8.0.74-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (49.1 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.1/49.1 MB\u001b[0m \u001b[31m14.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: Pillow>=7.1.2 in /usr/local/lib/python3.10/dist-packages (from roboflow) (9.4.0)\n","Collecting pyparsing==2.4.7 (from roboflow)\n","  Downloading pyparsing-2.4.7-py2.py3-none-any.whl (67 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.8/67.8 kB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: python-dateutil in /usr/local/lib/python3.10/dist-packages (from roboflow) (2.8.2)\n","Collecting python-dotenv (from roboflow)\n","  Downloading python_dotenv-1.0.0-py3-none-any.whl (19 kB)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from roboflow) (2.31.0)\n","Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from roboflow) (1.16.0)\n","Collecting supervision (from roboflow)\n","  Downloading supervision-0.14.0-py3-none-any.whl (63 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.3/63.3 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: urllib3>=1.26.6 in /usr/local/lib/python3.10/dist-packages (from roboflow) (2.0.4)\n","Requirement already satisfied: tqdm>=4.41.0 in /usr/local/lib/python3.10/dist-packages (from roboflow) (4.66.1)\n","Requirement already satisfied: PyYAML>=5.3.1 in /usr/local/lib/python3.10/dist-packages (from roboflow) (6.0.1)\n","Collecting requests-toolbelt (from roboflow)\n","  Downloading requests_toolbelt-1.0.0-py2.py3-none-any.whl (54 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.5/54.5 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->roboflow) (1.1.0)\n","Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->roboflow) (4.42.1)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->roboflow) (23.1)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->roboflow) (3.2.0)\n","Requirement already satisfied: scipy<2.0.0,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from supervision->roboflow) (1.11.2)\n","Installing collected packages: python-dotenv, pyparsing, opencv-python-headless, idna, cycler, chardet, certifi, supervision, requests-toolbelt, roboflow\n","  Attempting uninstall: pyparsing\n","    Found existing installation: pyparsing 3.1.1\n","    Uninstalling pyparsing-3.1.1:\n","      Successfully uninstalled pyparsing-3.1.1\n","  Attempting uninstall: opencv-python-headless\n","    Found existing installation: opencv-python-headless 4.8.0.76\n","    Uninstalling opencv-python-headless-4.8.0.76:\n","      Successfully uninstalled opencv-python-headless-4.8.0.76\n","  Attempting uninstall: idna\n","    Found existing installation: idna 3.4\n","    Uninstalling idna-3.4:\n","      Successfully uninstalled idna-3.4\n","  Attempting uninstall: cycler\n","    Found existing installation: cycler 0.11.0\n","    Uninstalling cycler-0.11.0:\n","      Successfully uninstalled cycler-0.11.0\n","  Attempting uninstall: chardet\n","    Found existing installation: chardet 5.2.0\n","    Uninstalling chardet-5.2.0:\n","      Successfully uninstalled chardet-5.2.0\n","  Attempting uninstall: certifi\n","    Found existing installation: certifi 2023.7.22\n","    Uninstalling certifi-2023.7.22:\n","      Successfully uninstalled certifi-2023.7.22\n","Successfully installed certifi-2022.12.7 chardet-4.0.0 cycler-0.10.0 idna-2.10 opencv-python-headless-4.8.0.74 pyparsing-2.4.7 python-dotenv-1.0.0 requests-toolbelt-1.0.0 roboflow-1.1.6 supervision-0.14.0\n"]},{"output_type":"display_data","data":{"application/vnd.colab-display-data+json":{"pip_warning":{"packages":["certifi","cycler","pyparsing"]}}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["loading Roboflow workspace...\n","loading Roboflow project...\n","[WARNING] we noticed you are downloading a `yolov8` datasets but you don't have `ultralytics` installed. Roboflow `.deploy` supports only models trained with `ultralytics==8.0.134`, to intall it `pip install ultralytics==8.0.134`.\n"]},{"output_type":"stream","name":"stderr","text":["Downloading Dataset Version Zip in facemask-1 to yolov8:: 100%|██████████| 58703/58703 [00:00<00:00, 62281.63it/s]"]},{"output_type":"stream","name":"stdout","text":["\n"]},{"output_type":"stream","name":"stderr","text":["\n","Extracting Dataset Version Zip to facemask-1 in yolov8:: 100%|██████████| 4012/4012 [00:00<00:00, 7228.74it/s]\n"]}]},{"cell_type":"code","source":["%pip install ultralytics\n","import ultralytics\n","ultralytics.checks()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5_DD3ZE3lldz","executionInfo":{"status":"ok","timestamp":1694689694026,"user_tz":-180,"elapsed":12643,"user":{"displayName":"M Elbaz","userId":"12079689995044965838"}},"outputId":"13ce1338-b0e6-4074-b9ff-7888b973b9e3"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stderr","text":["Ultralytics YOLOv8.0.178 🚀 Python-3.10.12 torch-2.0.1+cu118 CUDA:0 (Tesla T4, 15102MiB)\n","Setup complete ✅ (2 CPUs, 12.7 GB RAM, 26.5/78.2 GB disk)\n"]}]},{"cell_type":"code","source":["# Train YOLOv8n on COCO8 for 3 epochs\n","!yolo train model=yolov8n.pt data=/content/facemask-1/data.yaml epochs=3 imgsz=640"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dEt8rF_Ql2AT","executionInfo":{"status":"ok","timestamp":1694689875082,"user_tz":-180,"elapsed":156460,"user":{"displayName":"M Elbaz","userId":"12079689995044965838"}},"outputId":"574c039b-768e-4feb-f223-e7f3c31dd4cb"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["Ultralytics YOLOv8.0.178 🚀 Python-3.10.12 torch-2.0.1+cu118 CUDA:0 (Tesla T4, 15102MiB)\n","\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=detect, mode=train, model=yolov8n.pt, data=/content/facemask-1/data.yaml, epochs=3, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=None, workers=8, project=None, name=None, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/detect/train2\n","Downloading https://ultralytics.com/assets/Arial.ttf to '/root/.config/Ultralytics/Arial.ttf'...\n","100% 755k/755k [00:00<00:00, 17.1MB/s]\n","Overriding model.yaml nc=80 with nc=1\n","\n","                   from  n    params  module                                       arguments                     \n","  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n","  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n","  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n","  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n","  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n","  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n","  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n","  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n","  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n","  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n"," 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n"," 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 12                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n"," 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n"," 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 15                  -1  1     37248  ultralytics.nn.modules.block.C2f             [192, 64, 1]                  \n"," 16                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n"," 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 18                  -1  1    123648  ultralytics.nn.modules.block.C2f             [192, 128, 1]                 \n"," 19                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n"," 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 21                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n"," 22        [15, 18, 21]  1    751507  ultralytics.nn.modules.head.Detect           [1, [64, 128, 256]]           \n","Model summary: 225 layers, 3011043 parameters, 3011027 gradients\n","\n","Transferred 319/355 items from pretrained weights\n","\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/detect/train2', view at http://localhost:6006/\n","Freezing layer 'model.22.dfl.conv.weight'\n","\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n","\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n","\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/facemask-1/train/labels... 1400 images, 0 backgrounds, 0 corrupt: 100% 1400/1400 [00:00<00:00, 1705.35it/s]\n","\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /content/facemask-1/train/labels.cache\n","\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n","\u001b[34m\u001b[1mval: \u001b[0mScanning /content/facemask-1/valid/labels... 400 images, 0 backgrounds, 0 corrupt: 100% 400/400 [00:00<00:00, 814.08it/s]\n","\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /content/facemask-1/valid/labels.cache\n","Plotting labels to runs/detect/train2/labels.jpg... \n","\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n","\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.002, momentum=0.9) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.0005), 63 bias(decay=0.0)\n","Image sizes 640 train, 640 val\n","Using 2 dataloader workers\n","Logging results to \u001b[1mruns/detect/train2\u001b[0m\n","Starting training for 3 epochs...\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","        1/3      2.41G      1.491      1.712      1.778         26        640: 100% 88/88 [00:36<00:00,  2.44it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 13/13 [00:08<00:00,  1.52it/s]\n","                   all        400        400      0.916      0.895      0.966      0.492\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","        2/3      2.28G      1.439      1.232       1.68         15        640: 100% 88/88 [00:33<00:00,  2.65it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 13/13 [00:06<00:00,  1.94it/s]\n","                   all        400        400      0.987      0.974      0.994      0.545\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","        3/3      2.27G      1.405      1.019      1.636         17        640: 100% 88/88 [00:30<00:00,  2.87it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 13/13 [00:04<00:00,  3.13it/s]\n","                   all        400        400          1      0.989      0.995      0.564\n","\n","3 epochs completed in 0.034 hours.\n","Optimizer stripped from runs/detect/train2/weights/last.pt, 6.2MB\n","Optimizer stripped from runs/detect/train2/weights/best.pt, 6.2MB\n","\n","Validating runs/detect/train2/weights/best.pt...\n","Ultralytics YOLOv8.0.178 🚀 Python-3.10.12 torch-2.0.1+cu118 CUDA:0 (Tesla T4, 15102MiB)\n","Model summary (fused): 168 layers, 3005843 parameters, 0 gradients\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 13/13 [00:07<00:00,  1.67it/s]\n","                   all        400        400          1      0.989      0.995      0.563\n","Speed: 1.7ms preprocess, 2.3ms inference, 0.0ms loss, 2.2ms postprocess per image\n","Results saved to \u001b[1mruns/detect/train2\u001b[0m\n","💡 Learn more at https://docs.ultralytics.com/modes/train\n"]}]},{"cell_type":"code","source":["!cp -av /content/runs/detect/train /content/drive/MyDrive/yolo8record"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"87rs_dZdmy8i","executionInfo":{"status":"ok","timestamp":1694676819902,"user_tz":-180,"elapsed":392,"user":{"displayName":"M Elbaz","userId":"12079689995044965838"}},"outputId":"87a70d31-f074-49a4-b1f0-5a47a4b9d1a1"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["'/content/runs/detect/train' -> '/content/drive/MyDrive/yolo8record'\n","'/content/runs/detect/train/weights' -> '/content/drive/MyDrive/yolo8record/weights'\n","'/content/runs/detect/train/weights/last.pt' -> '/content/drive/MyDrive/yolo8record/weights/last.pt'\n","'/content/runs/detect/train/weights/best.pt' -> '/content/drive/MyDrive/yolo8record/weights/best.pt'\n","'/content/runs/detect/train/args.yaml' -> '/content/drive/MyDrive/yolo8record/args.yaml'\n","'/content/runs/detect/train/events.out.tfevents.1694676564.bde201419dd2.1057.0' -> '/content/drive/MyDrive/yolo8record/events.out.tfevents.1694676564.bde201419dd2.1057.0'\n","'/content/runs/detect/train/labels_correlogram.jpg' -> '/content/drive/MyDrive/yolo8record/labels_correlogram.jpg'\n","'/content/runs/detect/train/labels.jpg' -> '/content/drive/MyDrive/yolo8record/labels.jpg'\n","'/content/runs/detect/train/train_batch0.jpg' -> '/content/drive/MyDrive/yolo8record/train_batch0.jpg'\n","'/content/runs/detect/train/train_batch1.jpg' -> '/content/drive/MyDrive/yolo8record/train_batch1.jpg'\n","'/content/runs/detect/train/train_batch2.jpg' -> '/content/drive/MyDrive/yolo8record/train_batch2.jpg'\n","'/content/runs/detect/train/results.csv' -> '/content/drive/MyDrive/yolo8record/results.csv'\n","'/content/runs/detect/train/val_batch0_labels.jpg' -> '/content/drive/MyDrive/yolo8record/val_batch0_labels.jpg'\n","'/content/runs/detect/train/val_batch0_pred.jpg' -> '/content/drive/MyDrive/yolo8record/val_batch0_pred.jpg'\n","'/content/runs/detect/train/val_batch1_labels.jpg' -> '/content/drive/MyDrive/yolo8record/val_batch1_labels.jpg'\n","'/content/runs/detect/train/val_batch1_pred.jpg' -> '/content/drive/MyDrive/yolo8record/val_batch1_pred.jpg'\n","'/content/runs/detect/train/val_batch2_pred.jpg' -> '/content/drive/MyDrive/yolo8record/val_batch2_pred.jpg'\n","'/content/runs/detect/train/val_batch2_labels.jpg' -> '/content/drive/MyDrive/yolo8record/val_batch2_labels.jpg'\n","'/content/runs/detect/train/PR_curve.png' -> '/content/drive/MyDrive/yolo8record/PR_curve.png'\n","'/content/runs/detect/train/F1_curve.png' -> '/content/drive/MyDrive/yolo8record/F1_curve.png'\n","'/content/runs/detect/train/P_curve.png' -> '/content/drive/MyDrive/yolo8record/P_curve.png'\n","'/content/runs/detect/train/R_curve.png' -> '/content/drive/MyDrive/yolo8record/R_curve.png'\n","'/content/runs/detect/train/confusion_matrix_normalized.png' -> '/content/drive/MyDrive/yolo8record/confusion_matrix_normalized.png'\n","'/content/runs/detect/train/confusion_matrix.png' -> '/content/drive/MyDrive/yolo8record/confusion_matrix.png'\n","'/content/runs/detect/train/results.png' -> '/content/drive/MyDrive/yolo8record/results.png'\n"]}]},{"cell_type":"markdown","source":["**Applay validation**"],"metadata":{"id":"zHN6ycDpYcWG"}},{"cell_type":"code","source":["# Validate YOLOv8n on COCO8 val\n","!yolo val model=/content/runs/detect/train2/weights/best.pt data=/content/facemask-1/data.yaml  split=val"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"D8s3bNTLYT24","executionInfo":{"status":"ok","timestamp":1694690406038,"user_tz":-180,"elapsed":16063,"user":{"displayName":"M Elbaz","userId":"12079689995044965838"}},"outputId":"73a66639-e701-4f33-9744-332863d38905"},"execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":["Ultralytics YOLOv8.0.178 🚀 Python-3.10.12 torch-2.0.1+cu118 CUDA:0 (Tesla T4, 15102MiB)\n","Model summary (fused): 168 layers, 3005843 parameters, 0 gradients\n","\u001b[34m\u001b[1mval: \u001b[0mScanning /content/facemask-1/valid/labels.cache... 400 images, 0 backgrounds, 0 corrupt: 100% 400/400 [00:00<?, ?it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 25/25 [00:06<00:00,  4.17it/s]\n","                   all        400        400          1      0.989      0.995      0.564\n","Speed: 1.1ms preprocess, 4.8ms inference, 0.0ms loss, 2.1ms postprocess per image\n","Results saved to \u001b[1mruns/detect/val4\u001b[0m\n","💡 Learn more at https://docs.ultralytics.com/modes/val\n"]}]},{"cell_type":"code","source":["# Validate YOLOv8n on COCO8 val\n","!yolo val model=/content/runs/detect/train2/weights/best.pt data=/content/facemask-1/data.yaml split=test"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"KppNOGZpZLIS","executionInfo":{"status":"ok","timestamp":1694690447972,"user_tz":-180,"elapsed":14155,"user":{"displayName":"M Elbaz","userId":"12079689995044965838"}},"outputId":"73f89b33-5902-4b8a-e0fe-a1b3821d98fd"},"execution_count":11,"outputs":[{"output_type":"stream","name":"stdout","text":["Ultralytics YOLOv8.0.178 🚀 Python-3.10.12 torch-2.0.1+cu118 CUDA:0 (Tesla T4, 15102MiB)\n","Model summary (fused): 168 layers, 3005843 parameters, 0 gradients\n","\u001b[34m\u001b[1mval: \u001b[0mScanning /content/facemask-1/test/labels.cache... 200 images, 0 backgrounds, 0 corrupt: 100% 200/200 [00:00<?, ?it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 13/13 [00:04<00:00,  3.24it/s]\n","                   all        200        200          1      0.995      0.995      0.536\n","Speed: 2.3ms preprocess, 6.0ms inference, 0.0ms loss, 2.6ms postprocess per image\n","Results saved to \u001b[1mruns/detect/val5\u001b[0m\n","💡 Learn more at https://docs.ultralytics.com/modes/val\n"]}]}]}